{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import csv\n",
    "import glob\n",
    "from io import StringIO\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import trange\n",
    "\n",
    "from source.data_loader import MyDataLoader, WND\n",
    "from source.my3dpix2pix import My3dPix2Pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check inference result from training or validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load config\n",
    "spath = 'result/YOURFOLDER'\n",
    "\n",
    "with open(os.path.join(spath,'cfg.json')) as json_file:\n",
    "    cfg = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_feather(cfg['df_path'])\n",
    "DL = MyDataLoader(df0, cts=cfg['cts'], img_shape=cfg['img_shape'],\\\n",
    "                        grid=cfg['grid'],\\\n",
    "                        window1=cfg['window1'], window2=cfg['window2'], rescale_intensity=cfg['rescale_intensity'], splitvar=cfg['splitvar'])\n",
    "\n",
    "gan = My3dPix2Pix(DL, savepath=spath, L_weights=cfg['L_weights'], opt=cfg['opt'], lrs=cfg['lrs'],\\\n",
    "                        smoothlabel=cfg['smoothlabel'], fmloss=cfg['fmloss'],\\\n",
    "                        gennoise=cfg['gennoise'],\\\n",
    "                        randomshift=cfg['randomshift'], resoutput=cfg['resoutput'], dropout=cfg['dropout'],\\\n",
    "                        coordconv=cfg['coordconv'], resizeconv=cfg['resizeconv'], multigpu=cfg['multigpu'])\n",
    "\n",
    "gan.load_final_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check which cases are in training (0) or validation set (1)\n",
    "splitset = 0\n",
    "DL.case_split[splitset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run model on single case\n",
    "case = 0 # your case number\n",
    "pos = (0, 0, 8) # x,y fixed to 0, change z-axis number\n",
    "\n",
    "A, B = DL.imread_slice(case, pos, window=True, split=splitset)\n",
    "imgs_A = np.array([A])/127.5 - 1.\n",
    "imgs_B = np.array([B])/127.5 - 1.\n",
    "\n",
    "%time fake_A = gan.generator.predict(imgs_B)\n",
    "fake_AA = gan.invert_resoutput(fake_A, imgs_B)\n",
    "\n",
    "C = fake_A - imgs_B\n",
    "C[C<0] = 0\n",
    "fake_A = imgs_B+C\n",
    "\n",
    "gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## results\n",
    "r, c = 3, 3\n",
    "\n",
    "titles = ['Condition', 'Generated', 'Original']\n",
    "plt.style.use('default')\n",
    "fig, axs = plt.subplots(r, c, figsize=(3*c,3*r))\n",
    "for i in range(c):\n",
    "    for j in range(r):\n",
    "        fig0 = axs[j,i].imshow(gen_imgs[i][:,:,j,0], cmap='gray')\n",
    "        if j==0:\n",
    "            axs[j,i].set_title(titles[i])\n",
    "        fig.colorbar(fig0, ax=axs[j,i])\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test trained model on new test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe from dicoms\n",
    "dicom/YOURDATASET should be in following format:<br>\n",
    "YOURDATASET<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;case1<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CT1 containing dicom files<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CT2 containing dicom files<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;case2<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CT1 containing dicom files<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CT2 containing dicom files<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dicoms_to_dataframe(basedir, cts):\n",
    "    caselist = [os.path.join(basedir, x) for x in os.listdir(basedir) if os.path.isdir(os.path.join(basedir, x))]\n",
    "    file_list = []\n",
    "    for x in cts:\n",
    "        file_list.extend(glob.glob(os.path.join(basedir, '*/'+x+'/*.*')))\n",
    "\n",
    "    tdcmpath = os.path.join(caselist[0], cts[0])\n",
    "    tdcmpath = [os.path.join(tdcmpath, x) for x in os.listdir(tdcmpath) if x.lower().endswith('.dcm')][0]\n",
    "    tdcm = pydicom.dcmread(tdcmpath)\n",
    "\n",
    "    headers = []\n",
    "    headers.append('filepath')\n",
    "\n",
    "    for x in tdcm:\n",
    "        if x.name == 'Pixel Data':\n",
    "            continue\n",
    "        elif 'Overlay' in x.name or 'Referring' in x.name or 'Acquisition' in x.name:\n",
    "            continue\n",
    "        else:\n",
    "            name = x.name.replace(' ', '')\n",
    "            headers.append(name)\n",
    "\n",
    "    output = StringIO()\n",
    "    csv_writer = csv.DictWriter(output, fieldnames=headers)\n",
    "    csv_writer.writeheader()\n",
    "\n",
    "    for f in tqdm_notebook(file_list):\n",
    "        file = pydicom.dcmread(f)\n",
    "\n",
    "        row = {}\n",
    "        for x in file:\n",
    "            row['filepath'] = f\n",
    "            if x.name == 'Pixel Data':\n",
    "                continue\n",
    "            elif 'Overlay' in x.name or 'Referring' in x.name or 'Acquisition' in x.name:\n",
    "                continue\n",
    "            else:\n",
    "                name = x.name.replace(' ', '')\n",
    "                row[name] = x.value\n",
    "        unwanted = set(row) - set(headers)\n",
    "        for unwanted_key in unwanted: del row[unwanted_key]\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "    output.seek(0) # we need to get back to the start of the StringIO\n",
    "    df = pd.read_csv(output)\n",
    "\n",
    "    df['pid'] = df['filepath'].apply(lambda x: x.split(os.sep)[-3])\n",
    "    df['ct'] = df['filepath'].apply(lambda x: x.split(os.sep)[-2])\n",
    "    df['zpos'] = df['ImagePosition(Patient)'].apply(lambda x: [n.strip() for n in ast.literal_eval(x)][-1])\n",
    "\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-3:] + cols[:-3]\n",
    "    df = df[cols]\n",
    "\n",
    "    df.to_feather(os.path.join(basedir, 'headers.ftr'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CT1 = input, CT2 = output\n",
    "\n",
    "basedir = 'dicom/YOURTESTSET'\n",
    "cts = ('CT1','CT2')\n",
    "df = my_dicoms_to_dataframe(basedir, cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### modify headers and save\n",
    "\n",
    "df['zpos'] = df['zpos'].apply(pd.to_numeric)\n",
    "df = df.sort_values(by=['pid', 'ct', 'zpos'])\n",
    "df2 = df.reset_index(drop=True)\n",
    "df2path = os.path.join(basedir, 'select.ftr')\n",
    "df2.to_feather(df2path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop for inference on all cases in test set\n",
    "\n",
    "def loop_over_case(case, notruth=False):\n",
    "\n",
    "    pid, zs = case\n",
    "\n",
    "    dcm_A, dcm_B = gan.data_loader.load_dicoms(pid, (0,zs+1))\n",
    "    if notruth:\n",
    "        dcm_A = np.zeros(dcm_B.shape, dtype=dcm_B.dtype)\n",
    "\n",
    "    a = []\n",
    "    b = []\n",
    "    for w in gan.data_loader.window2:\n",
    "        a.append(WND(dcm_A,w))\n",
    "    for w in gan.data_loader.window1:\n",
    "        b.append(WND(dcm_B,w))  \n",
    "    tot_A = np.stack(a, axis=-1)\n",
    "    tot_B = np.stack(b, axis=-1)\n",
    "    tot_A = tot_A.astype('float32')/127.5 - 1.\n",
    "    tot_B = tot_B.astype('float32')/127.5 - 1.\n",
    "\n",
    "    fakes_raw = np.full((gan.img_rows,gan.img_cols,zs),0,dtype=tot_B.dtype)\n",
    "    counts_raw = np.full((gan.img_rows,gan.img_cols,zs),0,dtype=int)\n",
    "\n",
    "    for i in tqdm_notebook(range(zs+1-gan.depth)):\n",
    "        imgs_B = np.expand_dims(tot_B[:,:,i:i+gan.depth,:], axis=0)\n",
    "        fake_A = gan.generator.predict(imgs_B)\n",
    "        fake_A = 0.5 * fake_A + 0.5\n",
    "        fake_A = rWND(255.*fake_A[:,:,:,:,0], gan.data_loader.window2[0])\n",
    "\n",
    "        fakes_raw[:,:,i:i+gan.depth] += fake_A[0]\n",
    "        counts_raw[:,:,i:i+gan.depth] += 1\n",
    "\n",
    "    mcounts = counts_raw.copy()\n",
    "    mcounts[mcounts==0] = 1\n",
    "    fakes = np.divide(fakes_raw, mcounts)\n",
    "\n",
    "    # random sample\n",
    "    sample = np.random.choice(fakes.shape[-1])\n",
    "    sample = np.stack((\n",
    "        dcm_B[:,:,sample].astype(fakes.dtype),\n",
    "        fakes[:,:,sample],\n",
    "        dcm_A[:,:,sample].astype(fakes.dtype)\n",
    "    ), axis=-1)\n",
    "\n",
    "    df1 = gan.data_loader.df\n",
    "    dcms1 = df1[(df1['pid']==pid)&(df1['ct']==gan.data_loader.cts[0])]['filepath'].tolist()\n",
    "\n",
    "    newpath = os.path.join(savedir, pid)\n",
    "    if not os.path.isdir(newpath):\n",
    "        os.mkdir(newpath)\n",
    "    newpath = os.path.join(newpath, 'dicom')\n",
    "    if not os.path.isdir(newpath):\n",
    "        os.mkdir(newpath)\n",
    "\n",
    "    for N, y in tqdm_notebook(enumerate(dcms1)):\n",
    "        x = fakes[:,:,N]\n",
    "        ds = pydicom.dcmread(y)\n",
    "\n",
    "        x = (x-float(ds.RescaleIntercept))/float(ds.RescaleSlope)\n",
    "\n",
    "        x = x.astype('int16')\n",
    "\n",
    "        ds.PixelData = x.tobytes()\n",
    "\n",
    "        ds.SeriesNumber += 99000\n",
    "        ds.SOPInstanceUID += '.99'\n",
    "\n",
    "        newfile = os.path.join(newpath, os.path.basename(y))\n",
    "        ds.save_as(newfile)\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## load config + get new dicoms\n",
    "spath = 'result/YOURFOLDER'\n",
    "\n",
    "with open(os.path.join(spath,'cfg.json')) as json_file:\n",
    "    cfg = json.load(json_file)\n",
    "\n",
    "# your own test set and names of ct folders\n",
    "cfg['df_path'] = 'dicom/YOURTESTSET/select.ftr'\n",
    "cfg['cts'] = ('CT1','CT2')\n",
    "cfg['splitvar'] = 1.0  # fixed\n",
    "    \n",
    "df0 = pd.read_feather(cfg['df_path'])\n",
    "%time DL = MyDataLoader(df0, cts=cfg['cts'], img_shape=cfg['img_shape'],\\\n",
    "                grid=cfg['grid'],\\\n",
    "                window1=cfg['window1'], window2=cfg['window2'], rescale_intensity=cfg['rescale_intensity'], splitvar=cfg['splitvar'])\n",
    "\n",
    "%time gan = My3dPix2Pix(DL, savepath=spath, L_weights=cfg['L_weights'], opt=cfg['opt'], lrs=cfg['lrs'],\\\n",
    "                       smoothlabel=cfg['smoothlabel'], fmloss=cfg['fmloss'],\\\n",
    "                       gennoise=cfg['gennoise'],\\\n",
    "                       randomshift=cfg['randomshift'], resoutput=cfg['resoutput'], dropout=cfg['dropout'],\\\n",
    "                       coordconv=cfg['coordconv'], resizeconv=cfg['resizeconv'], multigpu=cfg['multigpu'])\n",
    "\n",
    "%time gan.load_final_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make directory for test results inside result/YOURFOLDER\n",
    "savedir = gan.make_directory('TESTDIRECTORY')\n",
    "split = 0\n",
    "L = gan.data_loader.case_split[split]\n",
    "choice = np.arange(len(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run loop\n",
    "samples = []\n",
    "\n",
    "for case in tqdm_notebook(choice):\n",
    "    samples.append(loop_over_case(L[case], notruth=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = len(samples)\n",
    "c = 3\n",
    "\n",
    "titles = ['Condition', 'Generated', 'Original']\n",
    "plt.style.use('default')\n",
    "fig, axs = plt.subplots(r, c, figsize=(3*c,3*r))\n",
    "for i in range(c):\n",
    "    axs[0,i].set_title(titles[i])\n",
    "    for j in range(r):\n",
    "        fig0 = axs[j,i].imshow(samples[j][:,:,i], cmap='gray')\n",
    "        fig.colorbar(fig0, ax=axs[j,i])\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
