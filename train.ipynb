{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import csv\n",
    "import glob\n",
    "from io import StringIO\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import trange\n",
    "\n",
    "from source.data_loader import MyDataLoader\n",
    "from source.my3dpix2pix import My3dPix2Pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe from dicoms\n",
    "dicom/YOURDATASET should be in following format:<br>\n",
    "YOURDATASET<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;case1<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CT1 containing dicom files<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CT2 containing dicom files<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;case2<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CT1 containing dicom files<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CT2 containing dicom files<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dicoms_to_dataframe(basedir, cts):\n",
    "    caselist = [os.path.join(basedir, x) for x in os.listdir(basedir) if os.path.isdir(os.path.join(basedir, x))]\n",
    "    file_list = []\n",
    "    for x in cts:\n",
    "        file_list.extend(glob.glob(os.path.join(basedir, '*/'+x+'/*.*')))\n",
    "\n",
    "    tdcmpath = os.path.join(caselist[0], cts[0])\n",
    "    tdcmpath = [os.path.join(tdcmpath, x) for x in os.listdir(tdcmpath) if x.lower().endswith('.dcm')][0]\n",
    "    tdcm = pydicom.dcmread(tdcmpath)\n",
    "\n",
    "    headers = []\n",
    "    headers.append('filepath')\n",
    "\n",
    "    for x in tdcm:\n",
    "        if x.name == 'Pixel Data':\n",
    "            continue\n",
    "        elif 'Overlay' in x.name or 'Referring' in x.name or 'Acquisition' in x.name:\n",
    "            continue\n",
    "        else:\n",
    "            name = x.name.replace(' ', '')\n",
    "            headers.append(name)\n",
    "\n",
    "    output = StringIO()\n",
    "    csv_writer = csv.DictWriter(output, fieldnames=headers)\n",
    "    csv_writer.writeheader()\n",
    "\n",
    "    for f in tqdm_notebook(file_list):\n",
    "        file = pydicom.dcmread(f)\n",
    "\n",
    "        row = {}\n",
    "        for x in file:\n",
    "            row['filepath'] = f\n",
    "            if x.name == 'Pixel Data':\n",
    "                continue\n",
    "            elif 'Overlay' in x.name or 'Referring' in x.name or 'Acquisition' in x.name:\n",
    "                continue\n",
    "            else:\n",
    "                name = x.name.replace(' ', '')\n",
    "                row[name] = x.value\n",
    "        unwanted = set(row) - set(headers)\n",
    "        for unwanted_key in unwanted: del row[unwanted_key]\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "    output.seek(0) # we need to get back to the start of the StringIO\n",
    "    df = pd.read_csv(output)\n",
    "\n",
    "    df['pid'] = df['filepath'].apply(lambda x: x.split(os.sep)[-3])\n",
    "    df['ct'] = df['filepath'].apply(lambda x: x.split(os.sep)[-2])\n",
    "    df['zpos'] = df['ImagePosition(Patient)'].apply(lambda x: [n.strip() for n in ast.literal_eval(x)][-1])\n",
    "\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-3:] + cols[:-3]\n",
    "    df = df[cols]\n",
    "\n",
    "    df.to_feather(os.path.join(basedir, 'headers.ftr'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CT1 = input, CT2 = output\n",
    "\n",
    "basedir = 'dicom/YOURDATASET'\n",
    "cts = ('CT1','CT2')\n",
    "df = my_dicoms_to_dataframe(basedir, cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### modify headers and save\n",
    "\n",
    "df['zpos'] = df['zpos'].apply(pd.to_numeric)\n",
    "df = df.sort_values(by=['pid', 'ct', 'zpos'])\n",
    "df2 = df.reset_index(drop=True)\n",
    "df2path = os.path.join(basedir, 'select.ftr')\n",
    "df2.to_feather(df2path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For new configuration and new result folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new config\n",
    "cfg = {\n",
    "    'df_path':'dicom/YOURDATASET/select.ftr',\n",
    "    'cts':('CT1','CT2'),\n",
    "    'img_shape':(512,512,16),\n",
    "    'window1':[(2000,0),(1000,200),(500,50)],\n",
    "    'window2':[(2000,0),(1000,200),(500,50)],\n",
    "    'batch_size':1,\n",
    "    'epochs':2,\n",
    "    'opt':'adam',\n",
    "    'lrs':(0.0002, 0.1),\n",
    "    'L_weights':(1,100),\n",
    "    'sample_interval':8,\n",
    "    'model_interval':5,\n",
    "    ## default\n",
    "    'grid':(1,1,1),\n",
    "    'splitvar':1.0,\n",
    "    'resizeconv':True,\n",
    "    'smoothlabel':True,\n",
    "    'rescale_intensity':False,\n",
    "    ## below not used\n",
    "    'coordconv':False,\n",
    "    'randomshift':0.1,\n",
    "    'gennoise':0,\n",
    "    'dropout':0.0,\n",
    "    'resoutput':0.0,\n",
    "    'fmloss':False,\n",
    "    'multigpu':None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df0 = pd.read_feather(cfg['df_path'])\n",
    "DL = MyDataLoader(df0, cts=cfg['cts'], img_shape=cfg['img_shape'],\n",
    "                  grid=cfg['grid'],\n",
    "                  window1=cfg['window1'], window2=cfg['window2'], rescale_intensity=cfg['rescale_intensity'], splitvar=cfg['splitvar'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save new config in new folder\n",
    "\n",
    "spath = 'result/YOURFOLDER'\n",
    "if not os.path.isdir(spath):\n",
    "    os.mkdir(spath)\n",
    "    \n",
    "split_path = os.path.join(spath, 'split.pkl')\n",
    "DL.save_split(split_path)\n",
    "cfg['splitvar'] = split_path\n",
    "    \n",
    "with open(os.path.join(spath,'cfg.json'), 'w') as json_file:\n",
    "    json.dump(cfg, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gan = My3dPix2Pix(DL, savepath=spath, L_weights=cfg['L_weights'], opt=cfg['opt'], lrs=cfg['lrs'],\n",
    "                  smoothlabel=cfg['smoothlabel'], fmloss=cfg['fmloss'],\n",
    "                  gennoise=cfg['gennoise'],\n",
    "                  randomshift=cfg['randomshift'], resoutput=cfg['resoutput'], dropout=cfg['dropout'],\n",
    "                  coordconv=cfg['coordconv'], resizeconv=cfg['resizeconv'], multigpu=cfg['multigpu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load config\n",
    "spath = 'result/YOURFOLDER'\n",
    "with open(os.path.join(spath, 'cfg.json')) as json_file:\n",
    "    cfg = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df0 = pd.read_feather(cfg['df_path'])\n",
    "DL = MyDataLoader(df0, cts=cfg['cts'], img_shape=cfg['img_shape'],\n",
    "                  grid=cfg['grid'],\n",
    "                  window1=cfg['window1'], window2=cfg['window2'], rescale_intensity=cfg['rescale_intensity'], splitvar=cfg['splitvar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gan = My3dPix2Pix(DL, savepath=spath, L_weights=cfg['L_weights'], opt=cfg['opt'], lrs=cfg['lrs'],\n",
    "                  smoothlabel=cfg['smoothlabel'], fmloss=cfg['fmloss'],\n",
    "                  gennoise=cfg['gennoise'],\n",
    "                  randomshift=cfg['randomshift'], resoutput=cfg['resoutput'], dropout=cfg['dropout'],\n",
    "                  coordconv=cfg['coordconv'], resizeconv=cfg['resizeconv'], multigpu=cfg['multigpu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.train(epochs=cfg['epochs'], batch_size=cfg['batch_size'], sample_interval=cfg['sample_interval'], model_interval=cfg['model_interval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view log\n",
    "#spath = 'result/YOURFOLDER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = []\n",
    "batch = []\n",
    "dloss = []\n",
    "gloss = []\n",
    "time = []\n",
    "with open(os.path.join(spath,'log.txt'), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        e,b,d,g,t = line.split('] ')\n",
    "        e = e.replace('[Epoch ','').split('/')[0]\n",
    "        b = b.replace('[Batch ','').split('/')[0]\n",
    "        d = d.replace('[D loss: ','').split(',')[0]\n",
    "        g = g.replace('[G loss: ','')\n",
    "        t = t.replace('time: ','')\n",
    "        \n",
    "        epoch.append(int(e))\n",
    "        batch.append(int(b))\n",
    "        dloss.append(float(d))\n",
    "        gloss.append(float(g))\n",
    "        time.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "x = np.arange(len(dloss)) + 1\n",
    "\n",
    "ax.plot(x, dloss, '-b', linewidth=0.1, label='d_loss')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(x, gloss, '-r', linewidth=0.1, label='g_loss')\n",
    "ax.set_ylim(-0.1,10)\n",
    "ax2.set_ylim(-0.1,20)\n",
    "\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper right')\n",
    "\n",
    "ax.set_title('model loss')\n",
    "ax.set_ylabel('d_loss')\n",
    "ax2.set_ylabel('g_loss')\n",
    "ax.set_xlabel('iteration')\n",
    "#fig.savefig(os.path.join(spath, 'loss.png'))\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
